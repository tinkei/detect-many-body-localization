{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 13*: Machine Learning of Many Body Localization (Exact diagonalization + Machine Learning)\n",
    "\n",
    "Use exact diagonalization to obtain all eigenstates of the the Heisenberg model with a\n",
    "random field, \n",
    "\n",
    "\\begin{equation}\n",
    "    H = J \\sum_i \\vec{S}_{i} \\cdot \\vec{S}_{i+1} - \\sum_i h_i S^z_i\n",
    "\\end{equation}\n",
    "\n",
    ", where the values of the field $ h_i \\in [-W, W] $ are chosen from a uniform random distribution with a \"disorder strength\" $W$ (Use moderate system sizes $L = [10, 12]$). \n",
    "\n",
    "The exciting property of this model is that it is believed to undergo a phase transition from an extended phase (small $W$) to a localized phase (large $W$). \n",
    "\n",
    "We will use ML to detect this transition: Pick a number of eigenstates that are near energy $E = 0$ and obtain the reduced density matrices $\\rho^A$, where $A$ is a region of $n$ consecutive spins (a few hundred to thousands eigenstates for different disorder realizations). \n",
    "\n",
    "Now use the density matrices for $W = 0.5 J$ and $W = 8.0 J$ to train a neural network (just interpret the entries of $\\rho^A$ as an image with $2^n \\times 2^n$ pixel). Then use this network and study the output of the neural network for different $W$. \n",
    "\n",
    "How does the results depend on system size $L$ and block size $n$? At which $W_c$ do you expect the\n",
    "transition to occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Author: Tin Kei CHENG_  \n",
    "_TUM, 2021_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numba import jit, njit # Set \"nopython\" mode for best performance, equivalent to @njit # cache=True, parallel=True\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "tz = pytz.timezone('Europe/Berlin')\n",
    "\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "from scipy.sparse import csr_matrix, kron, identity\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import svd\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "dpi = 100\n",
    "fig_w = 1280\n",
    "fig_h = 640\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if in_colab:\n",
    "    ED_data_dir = 'drive/MyDrive/Colab Data/CMMP/ED_data'\n",
    "    rho_train_data_dir = 'drive/MyDrive/Colab Data/CMMP/rho_train_data'\n",
    "    rho_valid_data_dir = 'drive/MyDrive/Colab Data/CMMP/rho_valid_data'\n",
    "    EVW_train_data_dir = 'drive/MyDrive/Colab Data/CMMP/EVW_train_data'\n",
    "    EVW_valid_data_dir = 'drive/MyDrive/Colab Data/CMMP/EVW_valid_data'\n",
    "    model_dir  = 'drive/MyDrive/Colab Data/CMMP/models'\n",
    "    signal_dir = 'drive/MyDrive/Colab Data/CMMP'\n",
    "else:\n",
    "    ED_data_dir = 'ED_data'\n",
    "    rho_train_data_dir = 'rho_train_data'\n",
    "    rho_valid_data_dir = 'rho_valid_data'\n",
    "    EVW_train_data_dir = 'EVW_train_data'\n",
    "    EVW_valid_data_dir = 'EVW_valid_data'\n",
    "    model_dir  = 'models'\n",
    "    signal_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if in_colab:\n",
    "    !cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if in_colab:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if in_colab:\n",
    "#     !pip install pytorch_lightning==0.7.6 torchsummary==1.5.1\n",
    "#     !pip install torch==1.4.0+cu92 torchvision==0.5.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pip install torch==1.4.0+cu92 torchsummary==1.5.1 torchvision==0.5.0+cu92 pytorch-lightning==0.7.6  -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import transforms\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "# from pytorch_lightning import Trainer, seed_everything\n",
    "# from pytorch_lightning.callbacks import EarlyStopping\n",
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "# # from torchsummary import summary\n",
    "# # help(summary)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # device = \"cpu\"\n",
    "# print(device)\n",
    "# # python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     13,
     35,
     59,
     81,
     85,
     118
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dt():\n",
    "    return datetime.now(tz=tz).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def dict_to_str(_dict):\n",
    "    \n",
    "    od = OrderedDict(sorted(_dict.items())) # Sort keys.\n",
    "    s = json.dumps(od) # Turn dict into str.\n",
    "    s = s[1:-1].replace('\\\"', '').replace(' ', '') # Replace some special characeters.\n",
    "    s = ''.join(x if x.isalnum() else ('=' if x == ':' else '_') for x in s) # Replace all remaining special characters.\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def save_cache(obj, obj_name, obj_params, cache_dir='cache'):\n",
    "    \"\"\"Cache an object, together with the parameters used to generate it.\n",
    "    For `obj_params`, try not to use nested dict or with complicated objects.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : object\n",
    "        An `object` you want to cache.\n",
    "    obj_name : str\n",
    "        A unique name you give to this object.\n",
    "    obj_params : dict\n",
    "        A `dict` of all parameters necessary to generate this object.\n",
    "    cache_dir : str, optional\n",
    "        Directory where the cache is located.\n",
    "    \"\"\"\n",
    "\n",
    "    param_str = dict_to_str(obj_params)\n",
    "    os.makedirs(os.path.join(cache_dir, obj_name), exist_ok=True)\n",
    "    with gzip.open(os.path.join(cache_dir, obj_name, param_str + '.pkl.gz'), 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_cache(obj_name, obj_params, cache_dir='cache'):\n",
    "    \"\"\"Check if the object is cached. If not, return None.\n",
    "    For `obj_params`, try not to use nested dict or with complicated objects.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj_name : str\n",
    "        A unique name you give to this object.\n",
    "    obj_params : dict\n",
    "        A `dict` of all parameters necessary to generate this object.\n",
    "    cache_dir : str, optional\n",
    "        Directory where the cache is located.\n",
    "    \"\"\"\n",
    "\n",
    "    param_str = dict_to_str(obj_params)\n",
    "    os.makedirs(os.path.join(cache_dir, obj_name), exist_ok=True)\n",
    "    if os.path.isfile(os.path.join(cache_dir, obj_name, param_str + '.pkl.gz')):\n",
    "        with gzip.open(os.path.join(cache_dir, obj_name, param_str + '.pkl.gz'), 'rb') as handle:\n",
    "            obj = pickle.load(handle)\n",
    "            return obj\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_shutdown_signal(signal_dir=signal_dir):\n",
    "    \"\"\"To gracefully stop generating data by making sure a loop is completed, this function will read a text file in a directory for the value `1`.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    shutdown : bool\n",
    "        Shutdown signal detected.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(os.path.join(signal_dir), exist_ok=True)\n",
    "    if os.path.isfile(os.path.join(signal_dir, 'shutdown_signal.txt')):\n",
    "        with open(os.path.join(signal_dir, 'shutdown_signal.txt')) as f:\n",
    "            lines = f.readlines()\n",
    "        if lines is not None and len(lines) > 0:\n",
    "            lines = [x.strip() for x in lines]\n",
    "            if lines[0] == '1':\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "@njit\n",
    "def is_sorted(arr):\n",
    "    return np.all(arr[:-1] <= arr[1:])\n",
    "\n",
    "\n",
    "def save_ED(obj, obj_name, L, W, periodic, data_dir=ED_data_dir):\n",
    "    \"\"\"Save a list of exact diagonalization results, organized by the parameters used to generate them.\n",
    "    For `obj_params`, try not to use nested dict or with complicated objects.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : list\n",
    "        A list of lists, where each reduced density matrix is paired with its disorder strength W.\n",
    "        Number of data must be a multiple of 10.\n",
    "    obj_name : str\n",
    "        A unique name you give to this object. Call it `rho_A`.\n",
    "    L : int\n",
    "        System size.\n",
    "    W : float\n",
    "        Disorder strength.\n",
    "    periodic : bool\n",
    "        Whether the Hamiltonian is periodic.\n",
    "    data_dir : str, optional\n",
    "        Directory where the data is saved.\n",
    "    \"\"\"\n",
    "\n",
    "    directory = os.path.join(data_dir, obj_name, 'L={:02d}'.format(L), 'W={:.2f}'.format(W), 'periodic={}'.format(periodic))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Check if file exists, and increment suffix.\n",
    "    i = 0\n",
    "    while os.path.exists(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i))):\n",
    "        i += 1\n",
    "\n",
    "    with gzip.open(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i)), 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_ED(obj_name, L, W, periodic, data_dir=ED_data_dir):\n",
    "    \"\"\"Check if the object is cached. If not, return None.\n",
    "    For `obj_params`, try not to use nested dict or with complicated objects.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj_name : str\n",
    "        A unique name you give to this object. Call it `rho_A`.\n",
    "    L : int\n",
    "        System size.\n",
    "    W : float\n",
    "        Disorder strength.\n",
    "    periodic : bool\n",
    "        Whether the Hamiltonian is periodic.\n",
    "    data_dir : str, optional\n",
    "        Directory where the data is saved.\n",
    "    \"\"\"\n",
    "\n",
    "    raise NotImplementedError('Function not implemented.')\n",
    "\n",
    "    param_str = dict_to_str(obj_params)\n",
    "    os.makedirs(os.path.join(data_dir, obj_name, 'L={:2d}'.format(L), 'W={:.2d}'.format(W)), exist_ok=True)\n",
    "    if os.path.isfile(os.path.join(data_dir, obj_name, 'L={:2d}'.format(L), 'W={:.2d}'.format(W), param_str + '.pkl.gz')):\n",
    "        with gzip.open(os.path.join(data_dir, obj_name, 'L={:2d}'.format(L), 'W={:.2d}'.format(W), param_str + '.pkl.gz'), 'rb') as handle:\n",
    "            obj = pickle.load(handle)\n",
    "            return obj\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     34
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_EVW_train(obj, obj_name, L, periodic, num_EV, data_dir=EVW_train_data_dir):\n",
    "    \"\"\"Save a list of reduced density matrices with W = {0.5, 8}.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : list\n",
    "        A list of lists, where each reduced density matrix is paired with its disorder strength W.\n",
    "        i.e. obj[i][0] is a 2D numpy.ndarray of the reduced density matrix, and obj[i][1] is the disorder strength used to generate it.\n",
    "        Number of data must be a multiple of 10.\n",
    "    obj_name : str\n",
    "        A name you give to this object. Call it `rho_A`.\n",
    "    L : int\n",
    "        System size.\n",
    "    periodic : bool\n",
    "        Whether the Hamiltonian is periodic.\n",
    "    num_EV : int\n",
    "        Number of eigenvalues around zero being sampled.\n",
    "    data_dir : str, optional\n",
    "        Directory where the data is saved.\n",
    "    \"\"\"\n",
    "\n",
    "    directory = os.path.join(data_dir, 'L={:02d}'.format(L), 'periodic={}'.format(periodic), 'num_EV={}'.format(num_EV))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Check if file exists, and increment suffix.\n",
    "    i = 0\n",
    "    while os.path.exists(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i))):\n",
    "        i += 1\n",
    "\n",
    "    with gzip.open(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i)), 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def save_EVW_valid(obj, obj_name, L, periodic, num_EV, data_dir=EVW_valid_data_dir):\n",
    "    \"\"\"Save a list of reduced density matrices with random W != {0.5, 8}.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : list\n",
    "        A list of lists, where each reduced density matrix is paired with its disorder strength W.\n",
    "        i.e. obj[i][0] is a 2D numpy.ndarray of the reduced density matrix, and obj[i][1] is the disorder strength used to generate it.\n",
    "        Number of data must be a multiple of 10.\n",
    "    obj_name : str\n",
    "        A name you give to this object. Call it `rho_A`.\n",
    "    L : int\n",
    "        System size.\n",
    "    periodic : bool\n",
    "        Whether the Hamiltonian is periodic.\n",
    "    num_EV : int\n",
    "        Number of eigenvalues around zero being sampled.\n",
    "    data_dir : str, optional\n",
    "        Directory where the data is saved.\n",
    "    \"\"\"\n",
    "\n",
    "    directory = os.path.join(data_dir, 'L={:02d}'.format(L), 'periodic={}'.format(periodic), 'num_EV={}'.format(num_EV))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Check if file exists, and increment suffix.\n",
    "    i = 0\n",
    "    while os.path.exists(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i))):\n",
    "        i += 1\n",
    "\n",
    "    with gzip.open(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i)), 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     38
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_EVW_train(obj_name, L, periodic, num_EV, data_dir=EVW_train_data_dir):\n",
    "    \"\"\"Load a list of reduced density matrices with W = {0.5, 8}.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj_name : str\n",
    "        A name you give to this object. Call it `rho_A`.\n",
    "    L : int\n",
    "        System size.\n",
    "    periodic : bool\n",
    "        Whether the Hamiltonian is periodic.\n",
    "    num_EV : int\n",
    "        Number of eigenvalues around zero being sampled.\n",
    "    data_dir : str, optional\n",
    "        Directory where the data is saved.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    obj : list\n",
    "        A list of lists, where each reduced density matrix is paired with its disorder strength W.\n",
    "        i.e. obj[i][0] is a 2D numpy.ndarray of the reduced density matrix, and obj[i][1] is the disorder strength used to generate it.\n",
    "        Number of data must be a multiple of 10.\n",
    "    \"\"\"\n",
    "\n",
    "    directory = os.path.join(data_dir, 'L={:02d}'.format(L), 'periodic={}'.format(periodic), 'num_EV={}'.format(num_EV))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Check if file exists, load the file, and increment suffix.\n",
    "    i = 0\n",
    "    data = []\n",
    "    while os.path.exists(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i))):\n",
    "        with gzip.open(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i)), 'rb') as handle:\n",
    "            data = data + pickle.load(handle)\n",
    "        i += 1\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_EVW_valid(obj_name, L, periodic, num_EV, data_dir=EVW_valid_data_dir):\n",
    "    \"\"\"Load a list of reduced density matrices with random W != {0.5, 8}.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj_name : str\n",
    "        A name you give to this object. Call it `rho_A`.\n",
    "    L : int\n",
    "        System size.\n",
    "    periodic : bool\n",
    "        Whether the Hamiltonian is periodic.\n",
    "    num_EV : int\n",
    "        Number of eigenvalues around zero being sampled.\n",
    "    data_dir : str, optional\n",
    "        Directory where the data is saved.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    obj : list\n",
    "        A list of lists, where each reduced density matrix is paired with its disorder strength W.\n",
    "        i.e. obj[i][0] is a 2D numpy.ndarray of the reduced density matrix, and obj[i][1] is the disorder strength used to generate it.\n",
    "        Number of data must be a multiple of 10.\n",
    "    \"\"\"\n",
    "\n",
    "    directory = os.path.join(data_dir, 'L={:02d}'.format(L), 'periodic={}'.format(periodic), 'num_EV={}'.format(num_EV))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Check if file exists, load the file, and increment suffix.\n",
    "    i = 0\n",
    "    data = []\n",
    "    while os.path.exists(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i))):\n",
    "        with gzip.open(os.path.join(directory, obj_name + '-{:09d}.pkl.gz'.format(i)), 'rb') as handle:\n",
    "            data = data + pickle.load(handle)\n",
    "        i += 1\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     18,
     28
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, file_name, L, n, periodic, num_EV, directory=model_dir):\n",
    "    \"\"\"Save model as pickle\"\"\"\n",
    "\n",
    "    model = model.cpu()\n",
    "    model_dict = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"hparams\": model.hparams\n",
    "    }\n",
    "\n",
    "    directory = os.path.join(directory, 'L={:02d}'.format(L), 'n={:02d}'.format(n), 'periodic={}'.format(periodic), 'num_EV={}'.format(num_EV))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    model_path = os.path.join(directory, file_name)\n",
    "    with gzip.open(model_path, 'wb', 4) as handle:\n",
    "        pickle.dump(model_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def load_model(file_name, L, n, periodic, num_EV, directory=model_dir):\n",
    "\n",
    "    directory = os.path.join(directory, 'L={:02d}'.format(L), 'n={:02d}'.format(n), 'periodic={}'.format(periodic), 'num_EV={}'.format(num_EV))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    model_path = os.path.join(directory, file_name)\n",
    "    with gzip.open(model_path, 'rb') as fp:\n",
    "        return pickle.load(fp)[\"state_dict\"]\n",
    "\n",
    "\n",
    "def model_exists(file_name, L, n, periodic, num_EV, directory=model_dir):\n",
    "\n",
    "    directory = os.path.join(directory, 'L={:02d}'.format(L), 'n={:02d}'.format(n), 'periodic={}'.format(periodic), 'num_EV={}'.format(num_EV))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    model_path = os.path.join(directory, file_name)\n",
    "    return os.path.exists(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build Hamiltonian and Exact Diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_h(L, W):\n",
    "    h = np.random.uniform(-W, W, L)\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_si_list(L):\n",
    "\n",
    "    # Get single site operaors.\n",
    "    sx = csr_matrix(np.array([[0.,  1. ], [1. ,  0.]]))\n",
    "    sy = csr_matrix(np.array([[0., -1.j], [1.j,  0.]]))\n",
    "    sz = csr_matrix(np.array([[1.,  0. ], [0. , -1.]]))\n",
    "    id = csr_matrix(np.eye(2))\n",
    "\n",
    "    # ========================================\n",
    "    # Start cached area: si_list.\n",
    "    # ========================================\n",
    "\n",
    "    obj_params = {'L': L}\n",
    "\n",
    "    sx_list = load_cache('sx_list', obj_params)\n",
    "    sy_list = load_cache('sy_list', obj_params)\n",
    "    sz_list = load_cache('sz_list', obj_params)\n",
    "\n",
    "    if sx_list is None or sy_list is None or sz_list is None:\n",
    "\n",
    "        # print('Cache not found for `si_list`. Generate from scratch.')\n",
    "\n",
    "        sx_list = []  # sx_list[i] = kron([id, id, ..., id, sx, id, .... id])\n",
    "        sy_list = []\n",
    "        sz_list = []\n",
    "\n",
    "        for i_site in range(L):\n",
    "\n",
    "            x_ops = [id] * L\n",
    "            y_ops = [id] * L\n",
    "            z_ops = [id] * L\n",
    "            x_ops[i_site] = sx\n",
    "            y_ops[i_site] = sy\n",
    "            z_ops[i_site] = sz\n",
    "\n",
    "            X = x_ops[0]\n",
    "            Y = y_ops[0]\n",
    "            Z = z_ops[0]\n",
    "            for j in range(1, L):\n",
    "                X = kron(X, x_ops[j], 'csr')\n",
    "                Y = kron(Y, y_ops[j], 'csr')\n",
    "                Z = kron(Z, z_ops[j], 'csr')\n",
    "            sx_list.append(X)\n",
    "            sy_list.append(Y)\n",
    "            sz_list.append(Z)\n",
    "\n",
    "        save_cache(sx_list, 'sx_list', obj_params)\n",
    "        save_cache(sy_list, 'sy_list', obj_params)\n",
    "        save_cache(sz_list, 'sz_list', obj_params)\n",
    "\n",
    "    # else:\n",
    "\n",
    "    #     print('Cache found for `si_list`. Load from cache.')\n",
    "\n",
    "    # ========================================\n",
    "    # End cached area: si_list.\n",
    "    # ========================================\n",
    "\n",
    "    return sx_list, sy_list, sz_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_H_ii(L, periodic):\n",
    "\n",
    "    sx_list, sy_list, sz_list = build_si_list(L)\n",
    "\n",
    "    # ========================================\n",
    "    # Start cached area: H_ii.\n",
    "    # ========================================\n",
    "    \n",
    "    obj_params = {'L': L, 'periodic': periodic}\n",
    "\n",
    "    H_xx = load_cache('H_xx', obj_params)\n",
    "    H_yy = load_cache('H_yy', obj_params)\n",
    "    H_zz = load_cache('H_zz', obj_params)\n",
    "\n",
    "    if H_xx is None or H_yy is None or H_zz is None:\n",
    "\n",
    "        # print('Cache not found for `H_ii`. Generate from scratch.')\n",
    "\n",
    "        H_xx = csr_matrix((2**L, 2**L))\n",
    "        H_yy = csr_matrix((2**L, 2**L))\n",
    "        H_zz = csr_matrix((2**L, 2**L))\n",
    "\n",
    "        for i in range(L if periodic else L - 1):\n",
    "            H_xx = H_xx + sx_list[i] * sx_list[(i + 1) % L]\n",
    "            H_yy = H_yy + sy_list[i] * sy_list[(i + 1) % L]\n",
    "            H_zz = H_zz + sz_list[i] * sz_list[(i + 1) % L]\n",
    "\n",
    "        save_cache(H_xx, 'H_xx', obj_params)\n",
    "        save_cache(H_yy, 'H_yy', obj_params)\n",
    "        save_cache(H_zz, 'H_zz', obj_params)\n",
    "\n",
    "    # else:\n",
    "\n",
    "    #     print('Cache found for `H_ii`. Load from cache.')\n",
    "\n",
    "    # ========================================\n",
    "    # End cached area: H_ii.\n",
    "    # ========================================\n",
    "\n",
    "    return H_xx, H_yy, H_zz, sx_list, sy_list, sz_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     15
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_H(L, W, J, periodic=False):\n",
    "\n",
    "    H_xx, H_yy, H_zz, sx_list, sy_list, sz_list = build_H_ii(L, periodic)\n",
    "\n",
    "    # H_z is not cached due to randomness.\n",
    "    H_z  = csr_matrix((2**L, 2**L))\n",
    "    h    = get_h(L, W)\n",
    "\n",
    "    for i in range(L):\n",
    "        H_z = H_z + h[i] * sz_list[i]\n",
    "\n",
    "    H = J * (H_xx + H_yy + H_zz) - H_z\n",
    "\n",
    "    return H\n",
    "\n",
    "def build_Hs(L, W, J, periodic=False, num_Hs=1000):\n",
    "\n",
    "    H_xx, H_yy, H_zz, sx_list, sy_list, sz_list = build_H_ii(L, periodic)\n",
    "\n",
    "    Hs = []\n",
    "    for i in tqdm(range(num_Hs), leave=False, desc='build_Hs()'):\n",
    "\n",
    "        # H_z is not cached due to randomness.\n",
    "        H_z  = csr_matrix((2**L, 2**L))\n",
    "        h    = get_h(L, W)\n",
    "\n",
    "        for i in range(L):\n",
    "            H_z = H_z + h[i] * sz_list[i]\n",
    "\n",
    "        H = J * (H_xx + H_yy + H_zz) - H_z\n",
    "        Hs.append(H)\n",
    "\n",
    "    return Hs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     32,
     67,
     105
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def ED(H):\n",
    "    \"\"\"For comparison: obtain ground state energy from exact diagonalization.\n",
    "\n",
    "    Exponentially expensive in L, only works for small enough `L` <~ 20.\n",
    "\n",
    "    The column V[:, i] is the normalized eigenvector corresponding to the eigenvalue E[i].\n",
    "    Will return a matrix object if a is a matrix object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : numpy.ndarray\n",
    "        Hamiltonian to diagonalize.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    E : 1D numpy.ndarray\n",
    "        Eigenvalues, sorted in ascending order.\n",
    "    V : 2D numpy.ndarray\n",
    "        Eigenvectors.\n",
    "    \"\"\"\n",
    "\n",
    "    # if L >= 20:\n",
    "    #     warnings.warn(\"Large L: Exact diagonalization might take a long time!\")\n",
    "\n",
    "    E, V = np.linalg.eigh(H)\n",
    "\n",
    "    assert is_sorted(E), 'Eigenvalues not sorted!'\n",
    "\n",
    "    return E, V\n",
    "\n",
    "\n",
    "def ED_sparse(H, k):\n",
    "    \"\"\"For comparison: obtain ground state energy from exact diagonalization.\n",
    "\n",
    "    Exponentially expensive in L, only works for small enough `L` <~ 20.\n",
    "\n",
    "    An array representing the k eigenvectors. The column v[:, i] is the eigenvector corresponding to the eigenvalue w[i].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : numpy.ndarray\n",
    "        Hamiltonian to diagonalize.\n",
    "    k : int\n",
    "        Number of eigenvalues around E = 0 to obtain.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    E : 1D numpy.ndarray\n",
    "        Eigenvalues, sorted in ascending order.\n",
    "    V : 2D numpy.ndarray\n",
    "        Eigenvectors.\n",
    "    \"\"\"\n",
    "\n",
    "    # if L >= 20:\n",
    "    #     warnings.warn(\"Large L: Exact diagonalization might take a long time!\")\n",
    "\n",
    "    E, V = scipy.sparse.linalg.eigsh(H, k=k, sigma=0, which='LM', return_eigenvectors=True)\n",
    "    sorted_indices = np.abs(E).argsort()\n",
    "    E = E[sorted_indices]\n",
    "    V = V[:, sorted_indices]\n",
    "\n",
    "    assert is_sorted(np.abs(E)), 'Eigenvalues not sorted!'\n",
    "\n",
    "    return E, V\n",
    "\n",
    "\n",
    "def EDs(Hs):\n",
    "    \"\"\"For comparison: obtain ground state energy from exact diagonalization.\n",
    "\n",
    "    Exponentially expensive in L, only works for small enough `L` <~ 20.\n",
    "\n",
    "    The column V[:, i] is the normalized eigenvector corresponding to the eigenvalue E[i].\n",
    "    Will return a matrix object if a is a matrix object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Hs : list of scipy.sparse.csr_matrix\n",
    "        A list of Hamiltonians to diagonalize.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    E : list of 1D numpy.ndarray\n",
    "        Eigenvalues of each Hamiltonian, sorted in ascending order.\n",
    "    V : list of 2D numpy.ndarray\n",
    "        Eigenvectors of each Hamiltonian.\n",
    "    \"\"\"\n",
    "\n",
    "    # if L >= 20:\n",
    "    #     warnings.warn(\"Large L: Exact diagonalization might take a long time!\")\n",
    "\n",
    "    Es = []\n",
    "    Vs = []\n",
    "    for H in Hs:\n",
    "\n",
    "        # Can't use scipy's eigsh, because we need ALL eigenwhatevers.\n",
    "        # E, V = eigsh(H, k=10, which='SM', return_eigenvectors=True)\n",
    "        # E, V = np.linalg.eigh(H.A)\n",
    "        E, V = ED(H.toarray())\n",
    "        Es.append(E)\n",
    "        Vs.append(V)\n",
    "\n",
    "    return Es, Vs\n",
    "\n",
    "\n",
    "def EDs_sparse(Hs, k):\n",
    "    \"\"\"For comparison: obtain ground state energy from exact diagonalization.\n",
    "\n",
    "    Exponentially expensive in L, only works for small enough `L` <~ 20.\n",
    "\n",
    "    An array representing the k eigenvectors. The column v[:, i] is the eigenvector corresponding to the eigenvalue w[i].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Hs : list of scipy.sparse.csr_matrix\n",
    "        A list of Hamiltonians to diagonalize.\n",
    "    k : int\n",
    "        Number of eigenvalues around E = 0 to obtain.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    E : 1D numpy.ndarray\n",
    "        Eigenvalues, sorted in ascending order.\n",
    "    V : 2D numpy.ndarray\n",
    "        Eigenvectors.\n",
    "    \"\"\"\n",
    "\n",
    "    # if L >= 20:\n",
    "    #     warnings.warn(\"Large L: Exact diagonalization might take a long time!\")\n",
    "\n",
    "    Es = []\n",
    "    Vs = []\n",
    "    for H in tqdm(Hs, leave=False, desc='EDs_sparse()'):\n",
    "\n",
    "        E, V = scipy.sparse.linalg.eigsh(H, k=k, sigma=0, which='LM', return_eigenvectors=True)\n",
    "        sorted_indices = np.abs(E).argsort()\n",
    "        E = E[sorted_indices]\n",
    "        V = V[:, sorted_indices]\n",
    "        Es.append(E)\n",
    "        Vs.append(V)\n",
    "\n",
    "    return Es, Vs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# @njit\n",
    "def select_N_eigenvalues(E, V, n, where='zeroest'):\n",
    "    \"\"\"\n",
    "    Select N eigenvalues closest to the lowest, to zero, or to the highest.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    E : 1D numpy.ndarray\n",
    "        Sorted eigenvalues in ascending order.\n",
    "    V : 2D numpy.ndarray\n",
    "        Corresponding eigenvectors.\n",
    "        The column V[:, i] is the normalized eigenvector corresponding to the eigenvalue E[i].\n",
    "    n : int\n",
    "        Number of eigenvalues to store.\n",
    "    where : str\n",
    "        Where to select the eigenvalues. where = {'lowest', 'zeroest', 'highest'}\n",
    "    \"\"\"\n",
    "\n",
    "    if where == 'lowest':\n",
    "        E = E[:n]\n",
    "        V = V[:, :n]\n",
    "    elif where == 'highest':\n",
    "        E = E[-n:]\n",
    "        V = V[:, -n:]\n",
    "    elif where == 'zeroest':\n",
    "        # closest_indices = np.abs(E).argsort()[:n]\n",
    "        # E = E[closest_indices]\n",
    "        # V = V[:, closest_indices]\n",
    "        # Faster implementation, but Numba doesn't support this. Still, it is a few microseconds faster.\n",
    "        # Source: https://stackoverflow.com/questions/16817948/i-have-need-the-n-minimum-index-values-in-a-numpy-array\n",
    "        closest_indices = np.argpartition(np.abs(E), n)[:n]\n",
    "        E_temp = E[closest_indices]\n",
    "        V_temp = V[:, closest_indices]\n",
    "        sorted_indices = np.abs(E_temp).argsort()[:n]\n",
    "        E = E_temp[sorted_indices]\n",
    "        V = V_temp[:, sorted_indices]\n",
    "        # assert np.all(E1 == E), 'Both sorting methods should be identical.'\n",
    "        # assert np.all(V1 == V), 'Both sorting methods should be identical.'\n",
    "\n",
    "    return E, V\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test solving a single Hamiltonian.\n",
    "L = 8\n",
    "W = 0.5\n",
    "J = 1\n",
    "periodic = False\n",
    "num_Hs = 10\n",
    "\n",
    "H = build_H(L, W, J, periodic=False)\n",
    "E, V = ED(H.toarray())\n",
    "print('2^L: {}'.format(2**L))\n",
    "print('#eigenvalues: {}'.format(len(E)))\n",
    "print('E.shape: {}'.format(E.shape))\n",
    "print('V.shape: {}'.format(V.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Solve using numpy's dense solver\n",
    "E, V = ED(H.toarray())\n",
    "E0, V0 = select_N_eigenvalues(E, V, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Solve using scipy's sparse solver instead.\n",
    "E1, V1 = ED_sparse(H, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Solve using numpy's dense solver\n",
    "E, V = ED(H.toarray())\n",
    "E0, V0 = select_N_eigenvalues(E, V, 20)\n",
    "# Solve using scipy's sparse solver instead.\n",
    "E1, V1 = ED_sparse(H, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check eigenvalues are sorted correctly, and eigenvectors are selected along the correct axis.\n",
    "V0_norm = []\n",
    "V1_norm = []\n",
    "for i in range(len(E0)):\n",
    "    V0_norm.append(np.linalg.norm(V0[:,i]))\n",
    "    V1_norm.append(np.linalg.norm(V1[:,i]))\n",
    "\n",
    "for E0i, E1i, V0i, V1i in zip(E0, E1, V0_norm, V1_norm):\n",
    "    print('Numpy: {:+.12f} | Numpy norm: {:.16f}'.format(E0i, V0i))\n",
    "    print('Scipy: {:+.12f} | Scipy norm: {:.16f}'.format(E1i, V1i))\n",
    "\n",
    "assert np.allclose(V0i, V1i), 'Eigenvectors evaluated using Numpy and Scipy should be identical.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test solving multiple Hamiltonians.\n",
    "Hs = build_Hs(L, W, J, periodic, num_Hs)\n",
    "Es, Vs = EDs(Hs)\n",
    "E0s, V0s = EDs_sparse(Hs, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_generate_ED_data(L, W, J=1, periodic=False, num_Hs=1000, num_EV=20, save_data=False, npsp='sp'):\n",
    "\n",
    "    obj_params = {'J': J, 'periodic': periodic} # Drop L and W. We use them for subdirectories.\n",
    "    Hs = build_Hs(L, W, J, periodic, num_Hs)\n",
    "\n",
    "    if npsp == 'sp':\n",
    "        E0s, V0s = EDs_sparse(Hs, num_EV)\n",
    "    else:\n",
    "        Es, Vs = EDs(Hs)\n",
    "        E0s = []\n",
    "        V0s = []\n",
    "        for E, V in zip(Es, Vs):\n",
    "            E0, V0 = select_N_eigenvalues(E, V, num_EV)\n",
    "            E0s.append(E0)\n",
    "            V0s.append(V0)\n",
    "\n",
    "    if save_data:\n",
    "        save_ED(E0s, 'E0s', L, W, periodic)\n",
    "        save_ED(V0s, 'V0s', L, W, periodic)\n",
    "\n",
    "    return E0s, V0s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test execution time.\n",
    "J  = 1                      # Always = 1\n",
    "Ws = [8]                    # Disorder strength W.\n",
    "Ls = list(range(8,12))      # System size L.\n",
    "ns = [1]*len(Ls)            # Number of samples for each L.\n",
    "ps = [False]                # Periodic or not.\n",
    "et = []                     # Execution time.\n",
    "num_EV = 20                 # Number of eigenvalues near zero to save.\n",
    "\n",
    "for L, num_Hs in zip(Ls, ns):\n",
    "    for W in Ws:\n",
    "        for p in ps:\n",
    "            start_time = time.time()\n",
    "            batch_generate_ED_data(L, W, J, p, num_Hs, num_EV, save_data=False, npsp='np')\n",
    "            exec_time = time.time() - start_time\n",
    "            et.append(exec_time)\n",
    "            print('Computed: L={:02d} | W={:.2f} | periodic={: <5}. Execution took {: 8.2f}s or {: 6.2f}min'.format(L, W, str(p), exec_time, exec_time/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(fig_w/dpi,fig_h/dpi), dpi=dpi, squeeze=False)\n",
    "\n",
    "base = 10\n",
    "axes[0,0].plot(Ls, et)\n",
    "axes[0,1].plot(np.array(Ls), np.log(et) / np.log(base))\n",
    "\n",
    "axes[0,0].set_title('Execution time vs System size')\n",
    "axes[0,1].set_title('Log(Execution time) vs System size')\n",
    "axes[0,0].set_ylabel('Execution time')\n",
    "axes[0,1].set_ylabel('Log(Execution time)')\n",
    "\n",
    "for axe in axes:\n",
    "    for ax in axe:\n",
    "        ax.set_xlabel('System size L')\n",
    "        # ax.legend(loc='best')\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test execution time.\n",
    "J  = 1                      # Always = 1\n",
    "Ws = [8]                    # Disorder strength W.\n",
    "Ls = list(range(8,16))      # System size L.\n",
    "ns = [1]*len(Ls)            # Number of samples for each L.\n",
    "ps = [False]                # Periodic or not.\n",
    "et = []                     # Execution time.\n",
    "num_EV = 20                 # Number of eigenvalues near zero to save.\n",
    "\n",
    "for L, num_Hs in zip(Ls, ns):\n",
    "    for W in Ws:\n",
    "        for p in ps:\n",
    "            start_time = time.time()\n",
    "            batch_generate_ED_data(L, W, J, p, num_Hs, num_EV, save_data=False, npsp='sp')\n",
    "            exec_time = time.time() - start_time\n",
    "            et.append(exec_time)\n",
    "            print('Computed: L={:02d} | W={:.2f} | periodic={: <5}. Execution took {: 8.2f}s or {: 6.2f}min'.format(L, W, str(p), exec_time, exec_time/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(fig_w/dpi,fig_h/dpi), dpi=dpi, squeeze=False)\n",
    "\n",
    "base = 10\n",
    "axes[0,0].plot(Ls, et)\n",
    "axes[0,1].plot(np.array(Ls), np.log(et) / np.log(base))\n",
    "\n",
    "axes[0,0].set_title('Execution time vs System size')\n",
    "axes[0,1].set_title('Log(Execution time) vs System size')\n",
    "axes[0,0].set_ylabel('Execution time')\n",
    "axes[0,1].set_ylabel('Log(Execution time)')\n",
    "\n",
    "for axe in axes:\n",
    "    for ax in axe:\n",
    "        ax.set_xlabel('System size L')\n",
    "        # ax.legend(loc='best')\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sample parameters.\n",
    "J  = 1                                 # Always = 1\n",
    "Ws = [0.5, 8] * 10 + [i/2 for i in range(1*2, 10*2)] # Disorder strength W.\n",
    "Ls = [   8,   9,  10,  11, 12, 13, 14] # System size L.\n",
    "ns = [1000, 500, 250, 100, 50, 20, 10] # Number of samples for each L.\n",
    "ps = [False, True]                     # Periodic or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test file size. It's not feasible to store all eigenvectors.\n",
    "J  = 1             # Always = 1\n",
    "Ws = [0.5, 8] * 10 + [i/2 for i in range(1*2, 10*2)] # Disorder strength W.\n",
    "Ls = [   8]        # System size L.\n",
    "ns = [1000]        # Number of samples for each L.\n",
    "ps = [False, True] # Periodic or not.\n",
    "\n",
    "fs = 0\n",
    "for L, num_Hs in zip(Ls, ns):\n",
    "    for W in Ws:\n",
    "        for p in ps:\n",
    "            start_time = time.time()\n",
    "            # batch_generate_ED_data(L, W, J, p, num_Hs)\n",
    "            fs += 1\n",
    "            exec_time = time.time() - start_time\n",
    "            # print('Computed: L={:02d} | W={:.2f} | periodic={: <5}. Execution took {: 8.2f}s or {: 6.2f}min'.format(L, W, str(p), exec_time, exec_time/60))\n",
    "print('Eigenvectors `Vs` dominates the file size. Assume 1000 samples are generated for each W, for around 20 Ws:')\n",
    "print('For L=8, each Es file is 2MB, Hs is 23MB, Vs is 1000MB.')\n",
    "print('Estimate file size of each run is thus {}MB'.format(fs*(2+23+1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('The full eigenvectors `Vs` dominates the file size.')\n",
    "for i in range(5):\n",
    "    print('For L = {:2d}, Vs is {:3d} MB.'.format(8+i, 4**i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Batch generate data and visualize eigenvectors for different W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_gen_EVW_data_core(L, Ws, J=1, periodic=False, num_Hs=1000, num_EV=5):\n",
    "\n",
    "    EVWs = []\n",
    "\n",
    "    for W in Ws:\n",
    "\n",
    "        Hs = build_Hs(L, W, J, periodic, num_Hs)\n",
    "        E0s, V0s = EDs_sparse(Hs, num_EV)\n",
    "\n",
    "        for E0, V0 in zip(E0s, V0s):\n",
    "            for i, E in enumerate(E0):\n",
    "                EVWs.append([E0[i], V0[:,i], W])\n",
    "\n",
    "    return EVWs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_gen_EVW_data_main(L, Ws, J=1, periodic=False, num_Hs=1000, num_EV=5, save_data=True):\n",
    "    \"\"\"Generate a list of eigenvectors with W = {0.5, 8}, and save them to file.\n",
    "    The data is used to train a classifier neutral network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    L : int\n",
    "        System size.\n",
    "    Ws : list of float\n",
    "        A list of disorder strength W to realize.\n",
    "    J : float\n",
    "        Coupling strength. Always set to 1.\n",
    "    periodic : bool\n",
    "        Whether the Hamiltonian is periodic.\n",
    "    num_Hs : int\n",
    "        Number of Hamiltonians to generate, per disorder strength W.\n",
    "    num_EV : int\n",
    "        Number of eigenvalues around zero to use as samples.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    EVWs : list of list\n",
    "        A list where each element is [E, V, W] = [eigenvalue, eigenvector, disorder strength].\n",
    "    \"\"\"\n",
    "\n",
    "    EVWs = batch_gen_EVW_data_core(L, Ws, J, periodic, num_Hs, num_EV)\n",
    "\n",
    "    if save_data:\n",
    "        print('Writing {: 5d} `EVW` of system size L = {:02d}.'.format(len(EVWs), L), flush=True)\n",
    "        save_EVW_train(EVWs, 'EVWs', L, periodic, num_EV)\n",
    "\n",
    "    return EVWs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_gen_EVW_data_rand(L, Ws, J=1, periodic=False, num_Hs=1000, num_EV=5, save_data=True):\n",
    "    \"\"\"Generate a list of eigenvectors with W = {0.5, 8}, and save them to file.\n",
    "    The data is used to train a classifier neutral network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    L : int\n",
    "        System size.\n",
    "    Ws : list of float\n",
    "        A list of disorder strength W to realize.\n",
    "    J : float\n",
    "        Coupling strength. Always set to 1.\n",
    "    periodic : bool\n",
    "        Whether the Hamiltonian is periodic.\n",
    "    num_Hs : int\n",
    "        Number of Hamiltonians to generate, per disorder strength W.\n",
    "    num_EV : int\n",
    "        Number of eigenvalues around zero to use as samples.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    EVWs : list of list\n",
    "        A list where each element is [E, V, W] = [eigenvalue, eigenvector, disorder strength].\n",
    "    \"\"\"\n",
    "\n",
    "    EVWs = batch_gen_EVW_data_core(L, Ws, J, periodic, num_Hs, num_EV)\n",
    "\n",
    "    if save_data:\n",
    "        print('Writing {: 5d} `EVW` of system size L = {:02d}.'.format(len(EVWs), L), flush=True)\n",
    "        save_EVW_valid(EVWs, 'EVWs', L, periodic, num_EV)\n",
    "\n",
    "    return EVWs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_samples = 2**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test drawing images of reduced density matrix.\n",
    "J  = 1                      # Always = 1\n",
    "Ws = [0.5, 8]               # Disorder strength W.\n",
    "Ls = [10]                   # System size L.\n",
    "Hs = [base_samples]         # Number of samples per L per W.\n",
    "ps = [False]                # Periodic or not.\n",
    "et = []                     # Execution time.\n",
    "num_EV = 1                  # Number of eigenvalues near zero to save.\n",
    "EVWs_main = []\n",
    "\n",
    "for L, num_Hs in zip(Ls, Hs):\n",
    "    for p in ps:\n",
    "        start_time = time.time()\n",
    "        EVWsi = batch_gen_EVW_data_main(L, Ws, J, p, num_Hs, num_EV, save_data=False)\n",
    "        EVWs_main.extend(EVWsi)\n",
    "        exec_time = time.time() - start_time\n",
    "        et.append(exec_time)\n",
    "        print('Computed: L={:02d} | periodic={: <5}.'.format(L, str(p)))\n",
    "        print('Execution took {: 8.2f}s or {: 6.2f}min.'.format(exec_time, exec_time/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(EVWs_main))       # = base_samples * len(Ws) * num_EV\n",
    "print(len(EVWs_main[0]))    # = 3\n",
    "print(len(EVWs_main[0][1])) # = 2**L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Wext_Vs = []\n",
    "Wloc_Vs = []\n",
    "\n",
    "for E, V, W in EVWs_main:\n",
    "\n",
    "    if W == 0.5:\n",
    "        Wext_Vs.append(V)\n",
    "    elif W == 8:\n",
    "        Wloc_Vs.append(V)\n",
    "\n",
    "Wext_Vs = np.array(Wext_Vs)\n",
    "Wloc_Vs = np.array(Wloc_Vs)\n",
    "print(Wext_Vs.shape)\n",
    "print(Wloc_Vs.shape)\n",
    "# Reshape due to `num_EV`.\n",
    "Wext_Vs = Wext_Vs.reshape(-1, 2**10)\n",
    "Wloc_Vs = Wext_Vs.reshape(-1, 2**10)\n",
    "print(Wext_Vs.shape)\n",
    "print(Wloc_Vs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(fig_w/dpi,fig_h/dpi), dpi=dpi, squeeze=False)\n",
    "\n",
    "axes[0,0].imshow(np.abs(Wext_Vs), vmin=0, vmax=1e-1)\n",
    "axes[0,0].annotate('W={:3.1f}'.format(0.5), (0.5,0.5), xycoords='axes fraction', ha='center', color='w')\n",
    "\n",
    "axes[0,1].imshow(np.abs(Wloc_Vs), vmin=0, vmax=1e-1)\n",
    "axes[0,1].annotate('W={:3.1f}'.format(8.0), (0.5,0.5), xycoords='axes fraction', ha='center', color='w')\n",
    "\n",
    "for axe in axes:\n",
    "    for ax in axe:\n",
    "        # ax.legend(loc='best')\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        # ax.xaxis.set_visible(False)\n",
    "        # ax.yaxis.set_visible(False)\n",
    "        ax.set_xlabel('Eigenvector coefficients')\n",
    "        ax.set_ylabel('Eigenvector samples')\n",
    "\n",
    "fig.tight_layout()\n",
    "print('Doesn\\'t seem to have any discernable patterns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch generate data (execution part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Batch generate eigenvectors.\n",
    "\n",
    "k = 1\n",
    "batches = 100\n",
    "base_sample = 100000 // k // batches # Divide by k (num_EV)\n",
    "rand_sample = 50            # Samples per random W.\n",
    "Ws_main = [0.5, 8]          # Disorder strength W.\n",
    "Ws_rand = np.random.uniform(0.1, high=5.9, size=(2 * base_sample // rand_sample,))\n",
    "J  = 1                      # Always = 1\n",
    "Ls = [10]                   # System sizes L.\n",
    "ps = [False, True]          # Periodic or not.\n",
    "et = []                     # Execution time.\n",
    "Hs_main = [base_sample]*len(Ls) # Number of samples per L per W.\n",
    "Hs_rand = [rand_sample]*len(Ls) # Number of samples per L per W.\n",
    "num_EVs = [k]               # Number of eigenvalues near zero to save.\n",
    "\n",
    "for i in range(batches):\n",
    "    print('{} | Processing batch {:03d} of {:d}:'.format(dt(), i+1, batches), flush=True)\n",
    "    print(' ', flush=True)\n",
    "    for L, num_Hs_m, num_Hs_r in zip(Ls, Hs_main, Hs_rand):\n",
    "        for num_EV in num_EVs:\n",
    "            for p in ps:\n",
    "                start_time = time.time()\n",
    "                print('{} | Generating training data for L={:02d}...'.format(dt(), L), flush=True)\n",
    "                batch_gen_EVW_data_main(L, Ws_main, J, p, num_Hs_m, num_EV, save_data=True)\n",
    "                print('{} | Generating random data for L={:02d}...'.format(dt(), L), flush=True)\n",
    "                batch_gen_EVW_data_rand(L, Ws_rand, J, p, num_Hs_r, num_EV, save_data=True)\n",
    "                exec_time = time.time() - start_time\n",
    "                et.append(exec_time)\n",
    "                dt = datetime.now(tz=tz).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print('{} | Computed: L={:02d} | num_EV={} | periodic={: <5}.'.format(dt(), L, num_EV, str(p)), flush=True)\n",
    "                print('{} | Execution took {: 8.2f}s or {: 6.2f}min.'.format(dt(), , exec_time, exec_time/60), flush=True)\n",
    "                print(' ', flush=True)\n",
    "\n",
    "    if check_shutdown_signal():\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "See the other notebook for training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "language": "python",
   "name": "python37264bit22d8f94fb4124d8cb7bc86dc616da5cb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
